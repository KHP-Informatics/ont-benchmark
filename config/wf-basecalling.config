// Parameters
params {
    // Input parameters
    input = null // specify in the CLI
    ref = null // leave as null - alignment and QC done with wf-alignment

    // Output parameters
    out_dir = null // specify in the CLI
    sample_name = null // specify in the CLI
    output_bam = true // wf-human-variation does not support CRAM files as input

    // Basecalling parameters
    basecaller_cfg = "dna_r10.4.1_e8.2_400bps_sup@v4.3.0" // default - specify in the CLI
    remora_cfg = "dna_r10.4.1_e8.2_400bps_sup@v4.3.0_5mCG_5hmCG@v1" // default - specify in the CLI
    dorado_ext = "pod5"
    qscore_filter = 0 // preferable to filter by mapping quality

    // Multithreading Parameters
    basecaller_basemod_threads = 2
    stats_threads = 4
    ubam_map_threads = 8
    ubam_sort_threads = 6
    ubam_bam2fq_threads = 2
    merge_threads = 8
}

// General workflow settings
workDir = "/scratch/prj/ppn_als_longread/work"
resume = true
cleanup = true

// Container settings
docker {
    enabled = false
}

singularity {
    enabled = true
    autoMounts = true
    cacheDir = "/scratch/users/${System.getenv('USER')}/singularity/cache"
}

executor {
    name = "slurm"
    queueSize = 50
}

// Process specific settings
process {
    queue = "cpu,nd_bioinformatics_cpu,interruptible_cpu"
    errorStrategy = "retry"
    maxRetries = 2
    time = { 1.h * task.attempt }

    withName: align_and_qsFilter { memory = { 32.GB * task.attempt }; time = { 8.h * task.attempt } }
    withName: qsFilter { cpus = 1; memory = { 1.GB * task.attempt }; time = { 5.min * task.attempt } }
    withName: merge_calls { memory = 32.GB; time = { 1.h * task.attempt } }
    withName: merge_calls_to_fastq { memory = 32.GB; time = { 1.h * task.attempt } }
    withName: checkBamHeaders { cpus = 1; memory = { 1.GB * task.attempt }; time = { 5.min * task.attempt } }
    withName: mergeBams { cpus = 8; memory = { 8.GB * task.attempt }; time = { 2.h * task.attempt } }
    withName: catSortBams { cpus = 10; memory = { 8.GB * task.attempt }; time = { 2.h * task.attempt } }
    withName: sortBam { cpus = 8; memory = { 8.GB * task.attempt }; time = { 2.h * task.attempt } }
    withName: move_or_compress_fq_file { cpus = 1; memory = 2.GB }
    withName: fastcat { cpus = 2; memory = { 8.GB * task.attempt } }
    withName: getVersions { cpus = 1; memory = 512.MB; time = { 5.min * task.attempt } }
    withName: getParams { cpus = 1; memory = 512.MB; time = { 5.min * task.attempt } }
    withName: cram_cache { cpus = 1; memory = { 1.GB * task.attempt }; time = { 10.min * task.attempt } }
    withName: bamstats { cpus = 2; memory = { 1.GB * task.attempt }; time = { 5.min * task.attempt } }
    withName: progressive_stats { cpus = 1; memory = 512.MB; time = { 5.min * task.attempt } }
    withName: split_xam { cpus = 2; memory = 8.GB }
    withName: pair_stats { cpus = 1; memory = 4.GB }
    withName: progressive_pairings { cpus = 1; memory = 4.GB }
    withName: makeReport { cpus = 1; memory = { 1.GB * task.attempt }; time = { 5.min * task.attempt } }
    withName: stopCondition { cpus = 1; memory = 512.MB; time = { 5.min * task.attempt } }
    withName: output_stream { cpus = 1; memory = 512.MB; time = { 5.min * task.attempt } }
    withName: output_last { cpus = 1; memory = 512.MB; time = { 5.min * task.attempt } }
    withName: output_pod5s { cpus = 1; memory = 4.GB }
    withName: make_mmi { cpus = 2; memory = 4.GB }
    withName: dorado_summary { cpus = 1; memory = 2.GB }
    withName: combine_dorado_summaries { cpus = 1; memory = 2.GB }

    // GPU-specific settings
    withLabel:gpu {
        queue = "biomed_a100_gpu,gpu,interruptible_gpu"
        containerOptions = "--nv" // Enabling NVIDIA GPU support in containers
        clusterOptions = "--gpus=2 --constraint=a100_80g" // Requesting 2 A100 80G GPUs per job to the SLURM executor
        maxForks = null // Requesting unlimited simultaneous GPU job executions
        cpus = 4
        memory = 16.GB
        time = { 15.min * task.attempt }
    }
}
